{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "038e695f",
   "metadata": {
    "papermill": {
     "duration": 0.009676,
     "end_time": "2023-12-25T15:18:18.149803",
     "exception": false,
     "start_time": "2023-12-25T15:18:18.140127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LSTM for stock prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844a8bb",
   "metadata": {
    "papermill": {
     "duration": 0.008723,
     "end_time": "2023-12-25T15:18:18.167482",
     "exception": false,
     "start_time": "2023-12-25T15:18:18.158759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f1609-bf25-49ec-b265-3ee42f36c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install torch==2.0.0 pandas numpy tqdm matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76ae4ab6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 5.359818,
     "end_time": "2023-12-25T15:18:23.536121",
     "exception": false,
     "start_time": "2023-12-25T15:18:18.176303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2edbf493-ade6-4831-9a1a-bd590d4afc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475b38d2-d447-4210-ab61-6221c9afc999",
   "metadata": {},
   "source": [
    "## Constants Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec82f829-fb3e-4504-83ab-667aff1502ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTENDED_FEATURES = [\n",
    "]\n",
    "NORMALIZED_FEATURE = [\n",
    "    'imbalance_size',\n",
    "    'matched_size',\n",
    "    'bid_size',\n",
    "    'ask_size'\n",
    "]\n",
    "FILL_ONE_FEATURES = [\n",
    "    \"reference_price\", \n",
    "    \"far_price\",\n",
    "    \"near_price\",\n",
    "    \"bid_price\",\n",
    "    \"ask_price\",\n",
    "    \"wap\"\n",
    "]\n",
    "FILL_MEAN_FEATURES = [\n",
    "    \"imbalance_size\", \n",
    "    \"matched_size\"\n",
    "]\n",
    "MODEL_INPUT_FEATURES = [\n",
    "    'imbalance_size', \n",
    "    'imbalance_buy_sell_flag',\n",
    "    'reference_price',\n",
    "    'matched_size',\n",
    "    'far_price',\n",
    "    'near_price',\n",
    "    'bid_price',\n",
    "    'bid_size',\n",
    "    'ask_price',\n",
    "    'ask_size',\n",
    "    'wap',\n",
    "    'target'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0457a3b8-1bc4-4549-8e87-2c1d222d520f",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2ddc5da8-8221-4872-8455-ed1b58f90072",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE: int = 256\n",
    "EPOCHS: int = 300\n",
    "LEARNING_RATE: float = 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba54e3b",
   "metadata": {
    "papermill": {
     "duration": 0.010149,
     "end_time": "2023-12-25T15:18:23.555675",
     "exception": false,
     "start_time": "2023-12-25T15:18:23.545526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6e99ff2",
   "metadata": {
    "papermill": {
     "duration": 18.68127,
     "end_time": "2023-12-25T15:18:42.280392",
     "exception": false,
     "start_time": "2023-12-25T15:18:23.599122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.010200</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237975</th>\n",
       "      <td>195</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>2440722.89</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>28280361.74</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>32257.04</td>\n",
       "      <td>1.000434</td>\n",
       "      <td>319862.40</td>\n",
       "      <td>1.000328</td>\n",
       "      <td>2.310276</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237976</th>\n",
       "      <td>196</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>349510.47</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>9187699.11</td>\n",
       "      <td>1.000129</td>\n",
       "      <td>1.000386</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>205108.40</td>\n",
       "      <td>1.000900</td>\n",
       "      <td>93393.07</td>\n",
       "      <td>1.000819</td>\n",
       "      <td>-8.220077</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237977</th>\n",
       "      <td>197</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>12725436.10</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>16790.66</td>\n",
       "      <td>0.995883</td>\n",
       "      <td>180038.32</td>\n",
       "      <td>0.995797</td>\n",
       "      <td>1.169443</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237978</th>\n",
       "      <td>198</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>1000898.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>94773271.05</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>125631.72</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>669893.00</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>-1.540184</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237979</th>\n",
       "      <td>199</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>1884285.71</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>24073677.32</td>\n",
       "      <td>1.000859</td>\n",
       "      <td>1.001494</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>250081.44</td>\n",
       "      <td>1.002447</td>\n",
       "      <td>300167.56</td>\n",
       "      <td>1.002274</td>\n",
       "      <td>-6.530285</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5237980 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0               0        0                  0      3180602.69   \n",
       "1               1        0                  0       166603.91   \n",
       "2               2        0                  0       302879.87   \n",
       "3               3        0                  0     11917682.27   \n",
       "4               4        0                  0       447549.96   \n",
       "...           ...      ...                ...             ...   \n",
       "5237975       195      480                540      2440722.89   \n",
       "5237976       196      480                540       349510.47   \n",
       "5237977       197      480                540            0.00   \n",
       "5237978       198      480                540      1000898.84   \n",
       "5237979       199      480                540      1884285.71   \n",
       "\n",
       "         imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                              1         0.999812   13380276.64        NaN   \n",
       "1                             -1         0.999896    1642214.25        NaN   \n",
       "2                             -1         0.999561    1819368.03        NaN   \n",
       "3                             -1         1.000171   18389745.62        NaN   \n",
       "4                             -1         0.999532   17860614.95        NaN   \n",
       "...                          ...              ...           ...        ...   \n",
       "5237975                       -1         1.000317   28280361.74   0.999734   \n",
       "5237976                       -1         1.000643    9187699.11   1.000129   \n",
       "5237977                        0         0.995789   12725436.10   0.995789   \n",
       "5237978                        1         0.999210   94773271.05   0.999210   \n",
       "5237979                       -1         1.002129   24073677.32   1.000859   \n",
       "\n",
       "         near_price  bid_price   bid_size  ask_price   ask_size       wap  \\\n",
       "0               NaN   0.999812   60651.50   1.000026    8493.03  1.000000   \n",
       "1               NaN   0.999896    3233.04   1.000660   20605.09  1.000000   \n",
       "2               NaN   0.999403   37956.00   1.000298   18995.00  1.000000   \n",
       "3               NaN   0.999999    2324.90   1.000214  479032.40  1.000000   \n",
       "4               NaN   0.999394   16485.54   1.000016     434.10  1.000000   \n",
       "...             ...        ...        ...        ...        ...       ...   \n",
       "5237975    0.999734   1.000317   32257.04   1.000434  319862.40  1.000328   \n",
       "5237976    1.000386   1.000643  205108.40   1.000900   93393.07  1.000819   \n",
       "5237977    0.995789   0.995789   16790.66   0.995883  180038.32  0.995797   \n",
       "5237978    0.999210   0.998970  125631.72   0.999210  669893.00  0.999008   \n",
       "5237979    1.001494   1.002129  250081.44   1.002447  300167.56  1.002274   \n",
       "\n",
       "           target  time_id       row_id  \n",
       "0       -3.029704        0        0_0_0  \n",
       "1       -5.519986        0        0_0_1  \n",
       "2       -8.389950        0        0_0_2  \n",
       "3       -4.010200        0        0_0_3  \n",
       "4       -7.349849        0        0_0_4  \n",
       "...           ...      ...          ...  \n",
       "5237975  2.310276    26454  480_540_195  \n",
       "5237976 -8.220077    26454  480_540_196  \n",
       "5237977  1.169443    26454  480_540_197  \n",
       "5237978 -1.540184    26454  480_540_198  \n",
       "5237979 -6.530285    26454  480_540_199  \n",
       "\n",
       "[5237980 rows x 17 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_dir = './kaggle'\n",
    "df = pd.read_csv(os.path.join(kaggle_dir, 'train.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f694b58f",
   "metadata": {
    "papermill": {
     "duration": 0.036399,
     "end_time": "2023-12-25T15:18:42.327346",
     "exception": false,
     "start_time": "2023-12-25T15:18:42.290947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5237980 entries, 0 to 5237979\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   stock_id                 int64  \n",
      " 1   date_id                  int64  \n",
      " 2   seconds_in_bucket        int64  \n",
      " 3   imbalance_size           float64\n",
      " 4   imbalance_buy_sell_flag  int64  \n",
      " 5   reference_price          float64\n",
      " 6   matched_size             float64\n",
      " 7   far_price                float64\n",
      " 8   near_price               float64\n",
      " 9   bid_price                float64\n",
      " 10  bid_size                 float64\n",
      " 11  ask_price                float64\n",
      " 12  ask_size                 float64\n",
      " 13  wap                      float64\n",
      " 14  target                   float64\n",
      " 15  time_id                  int64  \n",
      " 16  row_id                   object \n",
      "dtypes: float64(11), int64(5), object(1)\n",
      "memory usage: 679.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd2dfad6",
   "metadata": {
    "papermill": {
     "duration": 0.578321,
     "end_time": "2023-12-25T15:18:42.919211",
     "exception": false,
     "start_time": "2023-12-25T15:18:42.340890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stock_id                         0\n",
       "date_id                          0\n",
       "seconds_in_bucket                0\n",
       "imbalance_size                 220\n",
       "imbalance_buy_sell_flag          0\n",
       "reference_price                220\n",
       "matched_size                   220\n",
       "far_price                  2894342\n",
       "near_price                 2857180\n",
       "bid_price                      220\n",
       "bid_size                         0\n",
       "ask_price                      220\n",
       "ask_size                         0\n",
       "wap                            220\n",
       "target                          88\n",
       "time_id                          0\n",
       "row_id                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db4e14b",
   "metadata": {
    "papermill": {
     "duration": 10.259183,
     "end_time": "2023-12-25T15:18:53.188599",
     "exception": false,
     "start_time": "2023-12-25T15:18:42.929416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique</th>\n",
       "      <th>cardinality</th>\n",
       "      <th>with_null</th>\n",
       "      <th>null_pct</th>\n",
       "      <th>1st_row</th>\n",
       "      <th>random_row</th>\n",
       "      <th>last_row</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>199</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_id</th>\n",
       "      <td>False</td>\n",
       "      <td>481</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>480</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "      <td>540</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalance_size</th>\n",
       "      <td>False</td>\n",
       "      <td>2971863</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>2400918.36</td>\n",
       "      <td>1884285.71</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price</th>\n",
       "      <td>False</td>\n",
       "      <td>28741</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>0.997309</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matched_size</th>\n",
       "      <td>False</td>\n",
       "      <td>2948862</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>9135345.31</td>\n",
       "      <td>24073677.32</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price</th>\n",
       "      <td>False</td>\n",
       "      <td>95739</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.898997</td>\n",
       "      <td>1.000859</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price</th>\n",
       "      <td>False</td>\n",
       "      <td>84625</td>\n",
       "      <td>True</td>\n",
       "      <td>54.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979654</td>\n",
       "      <td>1.001494</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_price</th>\n",
       "      <td>False</td>\n",
       "      <td>28313</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>0.997309</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_size</th>\n",
       "      <td>False</td>\n",
       "      <td>2591773</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60651.5</td>\n",
       "      <td>345.72</td>\n",
       "      <td>250081.44</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_price</th>\n",
       "      <td>False</td>\n",
       "      <td>28266</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>0.997655</td>\n",
       "      <td>1.002447</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_size</th>\n",
       "      <td>False</td>\n",
       "      <td>2623254</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>10375.2</td>\n",
       "      <td>300167.56</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wap</th>\n",
       "      <td>False</td>\n",
       "      <td>31506</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99732</td>\n",
       "      <td>1.002274</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>False</td>\n",
       "      <td>15934</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>4.889965</td>\n",
       "      <td>-6.530285</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <td>False</td>\n",
       "      <td>26455</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1526</td>\n",
       "      <td>26454</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <td>True</td>\n",
       "      <td>5237980</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0_0_0</td>\n",
       "      <td>27_410_181</td>\n",
       "      <td>480_540_199</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         unique  cardinality  with_null  null_pct  \\\n",
       "stock_id                  False          200      False      0.00   \n",
       "date_id                   False          481      False      0.00   \n",
       "seconds_in_bucket         False           55      False      0.00   \n",
       "imbalance_size            False      2971863       True      0.00   \n",
       "imbalance_buy_sell_flag   False            3      False      0.00   \n",
       "reference_price           False        28741       True      0.00   \n",
       "matched_size              False      2948862       True      0.00   \n",
       "far_price                 False        95739       True     55.26   \n",
       "near_price                False        84625       True     54.55   \n",
       "bid_price                 False        28313       True      0.00   \n",
       "bid_size                  False      2591773      False      0.00   \n",
       "ask_price                 False        28266       True      0.00   \n",
       "ask_size                  False      2623254      False      0.00   \n",
       "wap                       False        31506       True      0.00   \n",
       "target                    False        15934       True      0.00   \n",
       "time_id                   False        26455      False      0.00   \n",
       "row_id                     True      5237980      False      0.00   \n",
       "\n",
       "                             1st_row  random_row     last_row    dtype  \n",
       "stock_id                           0         181          199    int64  \n",
       "date_id                            0          27          480    int64  \n",
       "seconds_in_bucket                  0         410          540    int64  \n",
       "imbalance_size            3180602.69  2400918.36   1884285.71  float64  \n",
       "imbalance_buy_sell_flag            1          -1           -1    int64  \n",
       "reference_price             0.999812    0.997309     1.002129  float64  \n",
       "matched_size             13380276.64  9135345.31  24073677.32  float64  \n",
       "far_price                        NaN    0.898997     1.000859  float64  \n",
       "near_price                       NaN    0.979654     1.001494  float64  \n",
       "bid_price                   0.999812    0.997309     1.002129  float64  \n",
       "bid_size                     60651.5      345.72    250081.44  float64  \n",
       "ask_price                   1.000026    0.997655     1.002447  float64  \n",
       "ask_size                     8493.03     10375.2    300167.56  float64  \n",
       "wap                              1.0     0.99732     1.002274  float64  \n",
       "target                     -3.029704    4.889965    -6.530285  float64  \n",
       "time_id                            0        1526        26454    int64  \n",
       "row_id                         0_0_0  27_410_181  480_540_199   object  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inspect_columns(df):\n",
    "\n",
    "    result = pd.DataFrame({\n",
    "        'unique': df.nunique() == len(df),\n",
    "        'cardinality': df.nunique(),\n",
    "        'with_null': df.isna().any(),\n",
    "        'null_pct': round((df.isnull().sum() / len(df)) * 100, 2),\n",
    "        '1st_row': df.iloc[0],\n",
    "        'random_row': df.iloc[np.random.randint(low=0, high=len(df))],\n",
    "        'last_row': df.iloc[-1],\n",
    "        'dtype': df.dtypes\n",
    "    })\n",
    "    return result\n",
    "\n",
    "inspect_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ff4ba-a541-40c9-a146-16075b276e6f",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c71fa615-9b51-4be9-becb-8e81d3e79d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_df = (4346980, 17)\n",
      "The shape of valid_df = (858000, 17)\n",
      "The shape of test_df = (34000, 17)\n"
     ]
    }
   ],
   "source": [
    "train_df: pd.DataFrame = df.loc[(0 <= df['date_id']) & (df['date_id'] <= 399)]\n",
    "valid_df: pd.DataFrame = df.loc[(400 <= df['date_id']) & (df['date_id'] <= 477)]\n",
    "test_df: pd.DataFrame = df.loc[((477 == df['date_id']) & (500 <= df['seconds_in_bucket'])) | ((478 <= df['date_id']) & (df['date_id'] <= 480))]\n",
    "\n",
    "print(f'The shape of train_df = {train_df.shape}')\n",
    "print(f'The shape of valid_df = {valid_df.shape}')\n",
    "print(f'The shape of test_df = {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9ac3a-d0af-4614-ad13-d6456dd86878",
   "metadata": {},
   "source": [
    "## Data Preprocessing After Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045094f-4882-413b-ab6e-319750f4cd7c",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6fcd041-20bb-4c1d-8aeb-5f9212816529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenPreprocessInfo(raw_df: pd.DataFrame) -> Dict[int, Dict[str, Dict[str, float]]]:\n",
    "    '''\n",
    "    Return value example:\n",
    "    {\n",
    "        'STOCK_ID': {\n",
    "            'COLUMN': {\n",
    "                'min': 0.0,\n",
    "                'max': 1.0,\n",
    "                'mean': 0.5\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    data: pd.DataFrame = raw_df.copy()\n",
    "    statistic_result: Dict[int, Dict[str, Dict[str, float]]] = {}\n",
    "    \n",
    "    for stock in data['stock_id'].unique().tolist():\n",
    "        stock_df: pd.DataFrame = data.loc[data['stock_id'] == stock]\n",
    "        stock_info: Dict[str, Dict[str, float]] = {}\n",
    "        \n",
    "        for feat in stock_df.columns:\n",
    "            if pd.api.types.is_string_dtype(stock_df[feat]):\n",
    "                continue\n",
    "            stock_feat_info: Dict[str, float] = {}\n",
    "            stock_feat_info['min'] = stock_df[feat].min(skipna=True)\n",
    "            stock_feat_info['max'] = stock_df[feat].max(skipna=True)\n",
    "            stock_feat_info['mean'] = stock_df[feat].mean(skipna=True)\n",
    "            stock_info[feat] = stock_feat_info\n",
    "        \n",
    "        statistic_result[stock] = stock_info\n",
    "    \n",
    "    return statistic_result\n",
    "\n",
    "preprocess_info = GenPreprocessInfo(raw_df=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd10edc0-fcf7-499b-b513-1c052e401d68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has nan: \n",
      "stock_id                   False\n",
      "date_id                    False\n",
      "seconds_in_bucket          False\n",
      "imbalance_size             False\n",
      "imbalance_buy_sell_flag    False\n",
      "reference_price            False\n",
      "matched_size               False\n",
      "far_price                  False\n",
      "near_price                 False\n",
      "bid_price                  False\n",
      "bid_size                   False\n",
      "ask_price                  False\n",
      "ask_size                   False\n",
      "wap                        False\n",
      "target                     False\n",
      "time_id                    False\n",
      "row_id                     False\n",
      "dtype: bool\n",
      "         stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
      "0               0        0                  0        0.023833   \n",
      "1               1        0                  0        0.014830   \n",
      "2               2        0                  0        0.015351   \n",
      "3               3        0                  0        0.037858   \n",
      "4               4        0                  0        0.005779   \n",
      "...           ...      ...                ...             ...   \n",
      "4346975       195      399                540        0.002781   \n",
      "4346976       196      399                540        0.021758   \n",
      "4346977       197      399                540        0.011443   \n",
      "4346978       198      399                540        0.000000   \n",
      "4346979       199      399                540        0.003262   \n",
      "\n",
      "         imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
      "0                              1         0.999812      0.041612   1.000000   \n",
      "1                             -1         0.999896      0.028287   1.000000   \n",
      "2                             -1         0.999561      0.003258   1.000000   \n",
      "3                             -1         1.000171      0.014849   1.000000   \n",
      "4                             -1         0.999532      0.051819   1.000000   \n",
      "...                          ...              ...           ...        ...   \n",
      "4346975                        1         0.998808      0.096884   0.999258   \n",
      "4346976                       -1         1.000274      0.149871   0.999756   \n",
      "4346977                        1         1.000543      0.029236   1.002325   \n",
      "4346978                        0         1.003443      0.081872   1.003443   \n",
      "4346979                        1         0.997327      0.021922   1.000154   \n",
      "\n",
      "         near_price  bid_price  bid_size  ask_price  ask_size       wap  \\\n",
      "0          1.000000   0.999812  0.010269   1.000026  0.008365  1.000000   \n",
      "1          1.000000   0.999896  0.006184   1.000660  0.027442  1.000000   \n",
      "2          1.000000   0.999403  0.077508   1.000298  0.010908  1.000000   \n",
      "3          1.000000   0.999999  0.001119   1.000214  0.374974  1.000000   \n",
      "4          1.000000   0.999394  0.010196   1.000016  0.000344  1.000000   \n",
      "...             ...        ...       ...        ...       ...       ...   \n",
      "4346975    0.998808   0.998695  0.086108   0.998808  0.192638  0.998756   \n",
      "4346976    0.999756   1.000274  0.147018   1.000533  0.157138  1.000343   \n",
      "4346977    1.001830   1.000444  0.049986   1.000543  0.049032  1.000509   \n",
      "4346978    1.003443   1.003166  0.652195   1.003443  0.373526  1.003316   \n",
      "4346979    0.998269   0.997013  0.109486   0.997327  0.105845  0.997254   \n",
      "\n",
      "           target  time_id       row_id  \n",
      "0       -3.029704        0        0_0_0  \n",
      "1       -5.519986        0        0_0_1  \n",
      "2       -8.389950        0        0_0_2  \n",
      "3       -4.010200        0        0_0_3  \n",
      "4       -7.349849        0        0_0_4  \n",
      "...           ...      ...          ...  \n",
      "4346975 -1.779795    21999  399_540_195  \n",
      "4346976 -7.029772    21999  399_540_196  \n",
      "4346977  5.110502    21999  399_540_197  \n",
      "4346978  2.870560    21999  399_540_198  \n",
      "4346979 -0.439882    21999  399_540_199  \n",
      "\n",
      "[4346893 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "def PreprocessTrainSet(\n",
    "    raw_df: pd.DataFrame, statistic_result: Dict[int, Dict[str, Dict[str, float]]]\n",
    ") -> pd.DataFrame:\n",
    "    data: pd.DataFrame = raw_df.copy()\n",
    "    \n",
    "    # fill out NaN with mean value\n",
    "    for stock in data['stock_id'].unique().tolist():\n",
    "        for feat in FILL_MEAN_FEATURES:\n",
    "            data.loc[\n",
    "                (data['stock_id'] == stock) & (data[feat].isnull()), \n",
    "                feat\n",
    "            ] = statistic_result[stock][feat]['mean']\n",
    "\n",
    "    # fill out NaN with 1\n",
    "    for feat in FILL_ONE_FEATURES:\n",
    "        data[feat] = data[feat].fillna(1.0)\n",
    "\n",
    "    # normalize features\n",
    "    for feat in MODEL_INPUT_FEATURES:\n",
    "        if feat not in NORMALIZED_FEATURE:\n",
    "            continue\n",
    "        data['min'] = np.nan\n",
    "        data['max'] = np.nan\n",
    "        \n",
    "        for stock in data['stock_id'].unique().tolist():\n",
    "            data.loc[data['stock_id'] == stock, ['min', 'max']] = [\n",
    "                statistic_result[stock][feat]['min'],\n",
    "                statistic_result[stock][feat]['max']\n",
    "            ]\n",
    "        \n",
    "        data[feat] = (data[feat] - data['min']) / (data['max'] - data['min'])\n",
    "        data = data.drop('min', axis=1)\n",
    "        data = data.drop('max', axis=1)\n",
    "        \n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    print(f'Data has nan: \\n{data.isnull().any()}')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "train_pp_df = PreprocessTrainSet(raw_df=train_df, statistic_result=preprocess_info)\n",
    "\n",
    "print(train_pp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32d644e-77b6-4538-9350-d8324fbf66a5",
   "metadata": {},
   "source": [
    "### Validation Set and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3fe10b3-9446-4c78-aa05-c2880f7fde2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreprocessValidationTestSet(\n",
    "    raw_df: pd.DataFrame, statistic_result: Dict[int, Dict[str, Dict[str, float]]]\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    data: pd.DataFrame = raw_df.copy()\n",
    "    \n",
    "    # fill out NaN with mean value\n",
    "    for stock in data['stock_id'].unique().tolist():\n",
    "        for feat in FILL_MEAN_FEATURES:\n",
    "            data.loc[\n",
    "                (data['stock_id'] == stock) & (data[feat].isnull()), \n",
    "                feat\n",
    "            ] = statistic_result[stock][feat]['mean']\n",
    "\n",
    "    # fill out NaN with 1\n",
    "    for feat in FILL_ONE_FEATURES:\n",
    "        data[feat] = data[feat].fillna(1.0)\n",
    "\n",
    "    # normalize features\n",
    "    for feat in MODEL_INPUT_FEATURES:\n",
    "        if feat not in NORMALIZED_FEATURE:\n",
    "            continue\n",
    "        data['min'] = np.nan\n",
    "        data['max'] = np.nan\n",
    "        \n",
    "        for stock in data['stock_id'].unique().tolist():\n",
    "            data.loc[data['stock_id'] == stock, ['min', 'max']] = [\n",
    "                statistic_result[stock][feat]['min'],\n",
    "                statistic_result[stock][feat]['max']\n",
    "            ]\n",
    "        \n",
    "        data[feat] = (data[feat] - data['min']) / (data['max'] - data['min'])\n",
    "        data = data.drop('min', axis=1)\n",
    "        data = data.drop('max', axis=1)\n",
    "        \n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    print(f'Data has nan: \\n{data.isnull().any()}')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67ac87c8-9ef3-425b-8824-0f9c6da9b230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has nan: \n",
      "stock_id                   False\n",
      "date_id                    False\n",
      "seconds_in_bucket          False\n",
      "imbalance_size             False\n",
      "imbalance_buy_sell_flag    False\n",
      "reference_price            False\n",
      "matched_size               False\n",
      "far_price                  False\n",
      "near_price                 False\n",
      "bid_price                  False\n",
      "bid_size                   False\n",
      "ask_price                  False\n",
      "ask_size                   False\n",
      "wap                        False\n",
      "target                     False\n",
      "time_id                    False\n",
      "row_id                     False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4346980</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104640</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>0.026447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999648</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>1.000521</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050068</td>\n",
       "      <td>22000</td>\n",
       "      <td>400_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346981</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998651</td>\n",
       "      <td>0.025849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998065</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>1.002580</td>\n",
       "      <td>0.045598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-10.010004</td>\n",
       "      <td>22000</td>\n",
       "      <td>400_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346982</th>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.097252</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000470</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>1.001236</td>\n",
       "      <td>0.103731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.070303</td>\n",
       "      <td>22000</td>\n",
       "      <td>400_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346983</th>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020171</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000143</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>1.000731</td>\n",
       "      <td>0.153409</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.780127</td>\n",
       "      <td>22000</td>\n",
       "      <td>400_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346984</th>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071687</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999428</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999255</td>\n",
       "      <td>0.016142</td>\n",
       "      <td>1.000119</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.590252</td>\n",
       "      <td>22000</td>\n",
       "      <td>400_0_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204975</th>\n",
       "      <td>195</td>\n",
       "      <td>477</td>\n",
       "      <td>540</td>\n",
       "      <td>0.040944</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.002359</td>\n",
       "      <td>0.120353</td>\n",
       "      <td>1.001253</td>\n",
       "      <td>1.001253</td>\n",
       "      <td>1.002359</td>\n",
       "      <td>0.153837</td>\n",
       "      <td>1.002482</td>\n",
       "      <td>0.318110</td>\n",
       "      <td>1.002429</td>\n",
       "      <td>-3.190041</td>\n",
       "      <td>26289</td>\n",
       "      <td>477_540_195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204976</th>\n",
       "      <td>196</td>\n",
       "      <td>477</td>\n",
       "      <td>540</td>\n",
       "      <td>0.045124</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.998663</td>\n",
       "      <td>0.148910</td>\n",
       "      <td>0.996644</td>\n",
       "      <td>0.997401</td>\n",
       "      <td>0.998663</td>\n",
       "      <td>0.078859</td>\n",
       "      <td>0.999168</td>\n",
       "      <td>0.079631</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>-6.200075</td>\n",
       "      <td>26289</td>\n",
       "      <td>477_540_196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204977</th>\n",
       "      <td>197</td>\n",
       "      <td>477</td>\n",
       "      <td>540</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997623</td>\n",
       "      <td>0.024257</td>\n",
       "      <td>0.998388</td>\n",
       "      <td>0.998388</td>\n",
       "      <td>0.997240</td>\n",
       "      <td>0.013190</td>\n",
       "      <td>0.997623</td>\n",
       "      <td>0.033533</td>\n",
       "      <td>0.997405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26289</td>\n",
       "      <td>477_540_197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204978</th>\n",
       "      <td>198</td>\n",
       "      <td>477</td>\n",
       "      <td>540</td>\n",
       "      <td>0.027363</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>0.054122</td>\n",
       "      <td>0.998511</td>\n",
       "      <td>0.998751</td>\n",
       "      <td>0.999712</td>\n",
       "      <td>0.249313</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.303272</td>\n",
       "      <td>0.999797</td>\n",
       "      <td>1.300573</td>\n",
       "      <td>26289</td>\n",
       "      <td>477_540_198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204979</th>\n",
       "      <td>199</td>\n",
       "      <td>477</td>\n",
       "      <td>540</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.996704</td>\n",
       "      <td>0.028876</td>\n",
       "      <td>0.996063</td>\n",
       "      <td>0.996063</td>\n",
       "      <td>0.996704</td>\n",
       "      <td>0.045153</td>\n",
       "      <td>0.997025</td>\n",
       "      <td>0.119507</td>\n",
       "      <td>0.996880</td>\n",
       "      <td>1.239777</td>\n",
       "      <td>26289</td>\n",
       "      <td>477_540_199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857999 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "4346980         0      400                  0        0.104640   \n",
       "4346981         1      400                  0        0.178324   \n",
       "4346982         2      400                  0        0.097252   \n",
       "4346983         3      400                  0        0.020171   \n",
       "4346984         4      400                  0        0.071687   \n",
       "...           ...      ...                ...             ...   \n",
       "5204975       195      477                540        0.040944   \n",
       "5204976       196      477                540        0.045124   \n",
       "5204977       197      477                540        0.004787   \n",
       "5204978       198      477                540        0.027363   \n",
       "5204979       199      477                540        0.001769   \n",
       "\n",
       "         imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "4346980                        1         0.999454      0.026447   1.000000   \n",
       "4346981                        1         0.998651      0.025849   1.000000   \n",
       "4346982                       -1         1.000470      0.011749   1.000000   \n",
       "4346983                        1         1.000143      0.032162   1.000000   \n",
       "4346984                        1         0.999428      0.008230   1.000000   \n",
       "...                          ...              ...           ...        ...   \n",
       "5204975                       -1         1.002359      0.120353   1.001253   \n",
       "5204976                       -1         0.998663      0.148910   0.996644   \n",
       "5204977                        1         0.997623      0.024257   0.998388   \n",
       "5204978                       -1         0.999832      0.054122   0.998511   \n",
       "5204979                       -1         0.996704      0.028876   0.996063   \n",
       "\n",
       "         near_price  bid_price  bid_size  ask_price  ask_size       wap  \\\n",
       "4346980    1.000000   0.999648  0.001736   1.000521  0.015102  1.000000   \n",
       "4346981    1.000000   0.998065  0.049754   1.002580  0.045598  1.000000   \n",
       "4346982    1.000000   0.999974  0.007547   1.001236  0.103731  1.000000   \n",
       "4346983    1.000000   0.999964  0.004982   1.000731  0.153409  1.000000   \n",
       "4346984    1.000000   0.999255  0.016142   1.000119  0.004565  1.000000   \n",
       "...             ...        ...       ...        ...       ...       ...   \n",
       "5204975    1.001253   1.002359  0.153837   1.002482  0.318110  1.002429   \n",
       "5204976    0.997401   0.998663  0.078859   0.999168  0.079631  0.998803   \n",
       "5204977    0.998388   0.997240  0.013190   0.997623  0.033533  0.997405   \n",
       "5204978    0.998751   0.999712  0.249313   0.999952  0.303272  0.999797   \n",
       "5204979    0.996063   0.996704  0.045153   0.997025  0.119507  0.996880   \n",
       "\n",
       "            target  time_id       row_id  \n",
       "4346980   0.050068    22000      400_0_0  \n",
       "4346981 -10.010004    22000      400_0_1  \n",
       "4346982   7.070303    22000      400_0_2  \n",
       "4346983   3.780127    22000      400_0_3  \n",
       "4346984   1.590252    22000      400_0_4  \n",
       "...            ...      ...          ...  \n",
       "5204975  -3.190041    26289  477_540_195  \n",
       "5204976  -6.200075    26289  477_540_196  \n",
       "5204977   0.000000    26289  477_540_197  \n",
       "5204978   1.300573    26289  477_540_198  \n",
       "5204979   1.239777    26289  477_540_199  \n",
       "\n",
       "[857999 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pp_df = PreprocessValidationTestSet(raw_df=valid_df, statistic_result=preprocess_info)\n",
    "valid_pp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7fedf3b-e18f-447b-994e-31e8f3e5bcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has nan: \n",
      "stock_id                   False\n",
      "date_id                    False\n",
      "seconds_in_bucket          False\n",
      "imbalance_size             False\n",
      "imbalance_buy_sell_flag    False\n",
      "reference_price            False\n",
      "matched_size               False\n",
      "far_price                  False\n",
      "near_price                 False\n",
      "bid_price                  False\n",
      "bid_size                   False\n",
      "ask_price                  False\n",
      "ask_size                   False\n",
      "wap                        False\n",
      "target                     False\n",
      "time_id                    False\n",
      "row_id                     False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5203980</th>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>500</td>\n",
       "      <td>0.010121</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.998733</td>\n",
       "      <td>0.149994</td>\n",
       "      <td>0.998383</td>\n",
       "      <td>0.998383</td>\n",
       "      <td>0.998733</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.998908</td>\n",
       "      <td>0.062429</td>\n",
       "      <td>0.998816</td>\n",
       "      <td>-1.959801</td>\n",
       "      <td>26285</td>\n",
       "      <td>477_500_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203981</th>\n",
       "      <td>1</td>\n",
       "      <td>477</td>\n",
       "      <td>500</td>\n",
       "      <td>0.019167</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.996861</td>\n",
       "      <td>0.230179</td>\n",
       "      <td>0.996761</td>\n",
       "      <td>0.996811</td>\n",
       "      <td>0.996861</td>\n",
       "      <td>0.022933</td>\n",
       "      <td>0.997110</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>-3.240108</td>\n",
       "      <td>26285</td>\n",
       "      <td>477_500_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203982</th>\n",
       "      <td>2</td>\n",
       "      <td>477</td>\n",
       "      <td>500</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000412</td>\n",
       "      <td>0.025736</td>\n",
       "      <td>1.000618</td>\n",
       "      <td>1.000618</td>\n",
       "      <td>1.000206</td>\n",
       "      <td>0.007384</td>\n",
       "      <td>1.000412</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>1.000306</td>\n",
       "      <td>2.800226</td>\n",
       "      <td>26285</td>\n",
       "      <td>477_500_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203983</th>\n",
       "      <td>3</td>\n",
       "      <td>477</td>\n",
       "      <td>500</td>\n",
       "      <td>0.023070</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.065996</td>\n",
       "      <td>0.998009</td>\n",
       "      <td>0.998603</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>1.000087</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>1.000011</td>\n",
       "      <td>-5.049705</td>\n",
       "      <td>26285</td>\n",
       "      <td>477_500_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203984</th>\n",
       "      <td>4</td>\n",
       "      <td>477</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.001033</td>\n",
       "      <td>0.075482</td>\n",
       "      <td>1.001033</td>\n",
       "      <td>1.001033</td>\n",
       "      <td>1.001033</td>\n",
       "      <td>0.093155</td>\n",
       "      <td>1.001089</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>1.001087</td>\n",
       "      <td>-1.299977</td>\n",
       "      <td>26285</td>\n",
       "      <td>477_500_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237975</th>\n",
       "      <td>195</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>0.035571</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>0.092998</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>0.011651</td>\n",
       "      <td>1.000434</td>\n",
       "      <td>0.311774</td>\n",
       "      <td>1.000328</td>\n",
       "      <td>2.310276</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237976</th>\n",
       "      <td>196</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>0.012758</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>0.155865</td>\n",
       "      <td>1.000129</td>\n",
       "      <td>1.000386</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>0.446159</td>\n",
       "      <td>1.000900</td>\n",
       "      <td>0.078257</td>\n",
       "      <td>1.000819</td>\n",
       "      <td>-8.220077</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237977</th>\n",
       "      <td>197</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.030443</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.995883</td>\n",
       "      <td>0.219793</td>\n",
       "      <td>0.995797</td>\n",
       "      <td>1.169443</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237978</th>\n",
       "      <td>198</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.090585</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>0.058164</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.209937</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>-1.540184</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237979</th>\n",
       "      <td>199</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>0.030855</td>\n",
       "      <td>1.000859</td>\n",
       "      <td>1.001494</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>0.054782</td>\n",
       "      <td>1.002447</td>\n",
       "      <td>0.212474</td>\n",
       "      <td>1.002274</td>\n",
       "      <td>-6.530285</td>\n",
       "      <td>26454</td>\n",
       "      <td>480_540_199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "5203980         0      477                500        0.010121   \n",
       "5203981         1      477                500        0.019167   \n",
       "5203982         2      477                500        0.008084   \n",
       "5203983         3      477                500        0.023070   \n",
       "5203984         4      477                500        0.000000   \n",
       "...           ...      ...                ...             ...   \n",
       "5237975       195      480                540        0.035571   \n",
       "5237976       196      480                540        0.012758   \n",
       "5237977       197      480                540        0.000000   \n",
       "5237978       198      480                540        0.004784   \n",
       "5237979       199      480                540        0.006047   \n",
       "\n",
       "         imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "5203980                       -1         0.998733      0.149994   0.998383   \n",
       "5203981                       -1         0.996861      0.230179   0.996761   \n",
       "5203982                        1         1.000412      0.025736   1.000618   \n",
       "5203983                       -1         0.999988      0.065996   0.998009   \n",
       "5203984                        0         1.001033      0.075482   1.001033   \n",
       "...                          ...              ...           ...        ...   \n",
       "5237975                       -1         1.000317      0.092998   0.999734   \n",
       "5237976                       -1         1.000643      0.155865   1.000129   \n",
       "5237977                        0         0.995789      0.030443   0.995789   \n",
       "5237978                        1         0.999210      0.090585   0.999210   \n",
       "5237979                       -1         1.002129      0.030855   1.000859   \n",
       "\n",
       "         near_price  bid_price  bid_size  ask_price  ask_size       wap  \\\n",
       "5203980    0.998383   0.998733  0.009558   0.998908  0.062429  0.998816   \n",
       "5203981    0.996811   0.996861  0.022933   0.997110  0.003114  0.997068   \n",
       "5203982    1.000618   1.000206  0.007384   1.000412  0.002194  1.000306   \n",
       "5203983    0.998603   0.999988  0.006517   1.000087  0.032960  1.000011   \n",
       "5203984    1.001033   1.001033  0.093155   1.001089  0.006674  1.001087   \n",
       "...             ...        ...       ...        ...       ...       ...   \n",
       "5237975    0.999734   1.000317  0.011651   1.000434  0.311774  1.000328   \n",
       "5237976    1.000386   1.000643  0.446159   1.000900  0.078257  1.000819   \n",
       "5237977    0.995789   0.995789  0.010616   0.995883  0.219793  0.995797   \n",
       "5237978    0.999210   0.998970  0.058164   0.999210  0.209937  0.999008   \n",
       "5237979    1.001494   1.002129  0.054782   1.002447  0.212474  1.002274   \n",
       "\n",
       "           target  time_id       row_id  \n",
       "5203980 -1.959801    26285    477_500_0  \n",
       "5203981 -3.240108    26285    477_500_1  \n",
       "5203982  2.800226    26285    477_500_2  \n",
       "5203983 -5.049705    26285    477_500_3  \n",
       "5203984 -1.299977    26285    477_500_4  \n",
       "...           ...      ...          ...  \n",
       "5237975  2.310276    26454  480_540_195  \n",
       "5237976 -8.220077    26454  480_540_196  \n",
       "5237977  1.169443    26454  480_540_197  \n",
       "5237978 -1.540184    26454  480_540_198  \n",
       "5237979 -6.530285    26454  480_540_199  \n",
       "\n",
       "[34000 rows x 17 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pp_df = PreprocessValidationTestSet(raw_df=test_df, statistic_result=preprocess_info)\n",
    "test_pp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3638b1b-b9f8-40e1-a609-e15fbcdb37b5",
   "metadata": {},
   "source": [
    "## Create DataLoaders for Training And Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "98e49a47-2eae-48eb-bb75-e7454651823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenTimeSeriesData(raw_df: pd.DataFrame) -> Tuple[np.ndarray, np.float32]:\n",
    "    '''\n",
    "    raw_df: The rows of time t-n ~ t for predicting the target of t.\n",
    "    The generated features contains the data of time t-n ~ t-1.\n",
    "    '''\n",
    "    df = raw_df.copy()\n",
    "    df = df.sort_values(by=['date_id', 'seconds_in_bucket'], ascending=True)\n",
    "    \n",
    "    df = df[MODEL_INPUT_FEATURES]\n",
    "    df_numpy: np.ndarray = df.to_numpy()\n",
    "    df_numpy[-1, MODEL_INPUT_FEATURES.index('target')] = 0\n",
    "    \n",
    "    x: np.ndarray = df_numpy\n",
    "    y: np.float32 = df['target'].tolist()[-1]\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def GenTimeSeriesDataset(\n",
    "    train_raw_df: pd.DataFrame, valid_raw_df: pd.DataFrame, window_size: int\n",
    ") -> Tuple[\n",
    "    np.ndarray, np.ndarray, np.ndarray, np.ndarray\n",
    "]:\n",
    "    '''\n",
    "    Generate train_x, train_y, valid_x, valid_y\n",
    "    '''\n",
    "    train_x: List[np.ndarray] = []\n",
    "    train_y: List[np.float32] = []\n",
    "    valid_x: List[np.ndarray] = []\n",
    "    valid_y: List[np.float32] = []\n",
    "    \n",
    "    data: pd.DataFrame = pd.concat([train_raw_df, valid_raw_df], ignore_index=True)\n",
    "    data = data.sort_values(by=['stock_id', 'date_id', 'seconds_in_bucket'], ascending=True)\n",
    "    train_date: List[int] = train_raw_df['date_id'].unique().tolist()\n",
    "    valid_date: List[int] = valid_raw_df['date_id'].unique().tolist()\n",
    "    \n",
    "    with tqdm(total=data.shape[0]) as pbar:\n",
    "        pbar.set_description('Preparing time series dataset')\n",
    "        for stock in data['stock_id'].unique().tolist():\n",
    "            stock_df: pd.DataFrame = data.loc[data['stock_id'] == stock].reset_index(drop=True)\n",
    "            stock_df.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            for date in range(0, 478):\n",
    "                for second in range(0, 540+1, 10):\n",
    "                    index_list: List[int] = stock_df.index[\n",
    "                        (stock_df['stock_id'] == stock) & \n",
    "                        (stock_df['date_id'] == date) & \n",
    "                        (stock_df['seconds_in_bucket'] == second)\n",
    "                    ].tolist()\n",
    "                    \n",
    "                    if len(index_list) == 0:\n",
    "                        continue\n",
    "                    pbar.update(1)\n",
    "                    if index_list[0] < window_size:\n",
    "                        continue\n",
    "                    \n",
    "                    x: np.ndarray\n",
    "                    y: np.float32\n",
    "                    start_idx, end_idx = index_list[0] - (window_size - 1), index_list[0] + 1\n",
    "                    x, y = GenTimeSeriesData(raw_df=stock_df.iloc[start_idx:end_idx])\n",
    "                    \n",
    "                    if date in train_date:\n",
    "                        train_x.append(x)\n",
    "                        train_y.append(y)\n",
    "                    elif date in valid_date:\n",
    "                        valid_x.append(x)\n",
    "                        valid_y.append(y)\n",
    "    \n",
    "    return np.array(train_x), np.array(train_y), np.array(valid_x), np.array(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dcfb5e9-941b-4cc8-8358-db2700a63ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing time series dataset: 100%|██████████| 5204892/5204892 [2:25:34<00:00, 595.93it/s]  \n"
     ]
    }
   ],
   "source": [
    "train_set_x: np.ndarray\n",
    "train_set_y: np.ndarray\n",
    "valid_set_x: np.ndarray\n",
    "valid_set_y: np.ndarray\n",
    "\n",
    "train_set_x, train_set_y, valid_set_x, valid_set_y = GenTimeSeriesDataset(\n",
    "    train_raw_df=train_pp_df, valid_raw_df=valid_pp_df, window_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f13a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x.astype(np.float32)\n",
    "train_set_y = train_set_y.astype(np.float32)\n",
    "valid_set_x = valid_set_x.astype(np.float32)\n",
    "valid_set_y = valid_set_y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e613a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_y = train_set_y[:, np.newaxis]\n",
    "valid_set_y = valid_set_y[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "40a46e54-f247-453e-ae6a-c342a597142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4345893, 5, 12)\n",
      "(4345893, 1)\n",
      "(857999, 5, 12)\n",
      "(857999, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_set_x.shape)\n",
    "print(train_set_y.shape)\n",
    "print(valid_set_x.shape)\n",
    "print(valid_set_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9893c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./numpy_bin/train_set_2_x.npy', 'wb') as f:\n",
    "    np.save(f, train_set_x)\n",
    "with open('./numpy_bin/train_set_2_y.npy', 'wb') as f:\n",
    "    np.save(f, train_set_y)\n",
    "with open('./numpy_bin/valid_set_2_x.npy', 'wb') as f:\n",
    "    np.save(f, valid_set_x)\n",
    "with open('./numpy_bin/valid_set_2_y.npy', 'wb') as f:\n",
    "    np.save(f, valid_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7355a393-999c-464b-b327-c6d73d249d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = np.load('./numpy_bin/train_set_2_x.npy').astype(np.float32)\n",
    "train_set_y = np.load('./numpy_bin/train_set_2_y.npy').astype(np.float32)\n",
    "valid_set_x = np.load('./numpy_bin/valid_set_2_x.npy').astype(np.float32)\n",
    "valid_set_y = np.load('./numpy_bin/valid_set_2_y.npy').astype(np.float32)\n",
    "\n",
    "if train_set_y.ndim == 1:\n",
    "    train_set_y = train_set_y[:, np.newaxis]\n",
    "if valid_set_y.ndim == 1:\n",
    "    valid_set_y = valid_set_y[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f1abd72-a8cb-46e9-a74e-ea57996ab6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4345893, 5, 12)\n",
      "(4345893, 1)\n",
      "(857999, 5, 12)\n",
      "(857999, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_set_x.shape)\n",
    "print(train_set_y.shape)\n",
    "print(valid_set_x.shape)\n",
    "print(valid_set_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "63eb8dbe-cdde-4e46-badd-358a3aa9b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_torch, train_set_y_torch, valid_set_x_torch, valid_set_y_torch = (\n",
    "    torch.tensor(train_set_x).clone().detach(),\n",
    "    torch.tensor(train_set_y).clone().detach(),\n",
    "    torch.tensor(valid_set_x).clone().detach(),\n",
    "    torch.tensor(valid_set_y).clone().detach()\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_set_x_torch, train_set_y_torch), shuffle=True, batch_size=BATCH_SIZE)\n",
    "valid_loader = DataLoader(TensorDataset(valid_set_x_torch, valid_set_y_torch), shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86aa0f0-33f7-49d2-937b-76b4a11dc25b",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e1b980b4-e13a-45b8-9c61-dd65e2c9c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.cnn_1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.lstm_1 = nn.LSTM(\n",
    "            input_size=128, \n",
    "            hidden_size=64, \n",
    "            num_layers=2, \n",
    "            batch_first=True\n",
    "        )\n",
    "        # self.linear_1 = nn.Linear(64 * 2, 64)\n",
    "        # self.tanh_1 = nn.Tanh()\n",
    "        # self.linear_2 = nn.Linear(64, 64)\n",
    "        # self.tanh_2 = nn.Tanh()\n",
    "        self.linear_3 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #cnn takes input of shape (batch_size, channels, seq_len)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out = self.cnn_1(x)\n",
    "        \n",
    "        # lstm takes input of shape (batch_size, seq_len, input_size)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out, _ = self.lstm_1(out)\n",
    "        out = self.linear_3(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0d67b4-3c71-4d15-b3f4-b9d26b280823",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fcdcce33-2f75-4d67-9ab3-a266c8ec4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, train_loader: DataLoader, valid_loader: DataLoader, optimizer, loss_fn, epoch_cnt: int\n",
    ") -> Tuple[List[float], List[float]]:\n",
    "    train_loss_list: List[float] = []\n",
    "    valid_loss_list: List[float] = []\n",
    "    \n",
    "    print(f'The batch size of train_loader = {train_loader.batch_size}')\n",
    "    print(f'The batch size of valid_loader = {valid_loader.batch_size}')\n",
    "\n",
    "    min_loss: float = 10.0\n",
    "    \n",
    "    for epoch in range(epoch_cnt):\n",
    "        train_batch_loss_list: List[float] = []\n",
    "        valid_batch_loss_list: List[float] = []\n",
    "        \n",
    "        model.train()\n",
    "        pbar = tqdm(train_loader)\n",
    "        pbar.set_description(f\"Training Epoch {epoch}\")\n",
    "        for batch_x, batch_y in pbar:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred_y = model(batch_x)\n",
    "            loss = loss_fn(pred_y, batch_y)\n",
    "            train_batch_loss_list.append(loss.cpu().detach().numpy())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if len(train_batch_loss_list) % 1000 == 999:\n",
    "                train_loss_list.append(float(np.mean(train_batch_loss_list[-100:])))\n",
    "        \n",
    "        model.eval()\n",
    "        better_model: bool = False\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(valid_loader)\n",
    "            pbar.set_description(f\"Validating Epoch {epoch}\")\n",
    "            for batch_x, batch_y in pbar:\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                \n",
    "                pred_y = model(batch_x)\n",
    "                loss = loss_fn(pred_y, batch_y)\n",
    "                valid_batch_loss_list.append(loss.cpu().detach().numpy())\n",
    "\n",
    "                if len(valid_batch_loss_list) % 1000 == 999:\n",
    "                    if len(valid_loss_list) == 0 or float(np.mean(valid_batch_loss_list[-1000:])) < min_loss:\n",
    "                        better_model = True\n",
    "                        min_loss = float(np.mean(valid_batch_loss_list[-1000:]))\n",
    "                    valid_loss_list.append(float(np.mean(valid_batch_loss_list[-1000:])))\n",
    "\n",
    "        if better_model:\n",
    "            torch.save(model, f\"./models/cnn-lstm-bs[{BATCH_SIZE}]-lr[{LEARNING_RATE}].pt\")\n",
    "        \n",
    "        print(\"Epoch %d: train_loss %.4f, val_loss %.4f\" % (epoch, np.mean(train_batch_loss_list), np.mean(valid_batch_loss_list)))\n",
    "        \n",
    "    return train_loss_list, valid_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "61753e46-7e47-4309-8148-0160227cbd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_Model(\n",
       "  (cnn_1): Sequential(\n",
       "    (0): Conv1d(12, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm_1): LSTM(128, 64, num_layers=2, batch_first=True)\n",
       "  (linear_3): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_Model(input_size=len(MODEL_INPUT_FEATURES))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "001d47ff-1046-4f90-ac54-b041b808edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bf9af786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch size of train_loader = 16\n",
      "The batch size of valid_loader = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|██████████| 271619/271619 [07:42<00:00, 587.32it/s]\n",
      "Validating Epoch 0: 100%|██████████| 53625/53625 [00:33<00:00, 1584.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss 4.2201, val_loss 3.6535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 271619/271619 [07:44<00:00, 584.15it/s]\n",
      "Validating Epoch 1: 100%|██████████| 53625/53625 [00:33<00:00, 1588.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss 4.1335, val_loss 3.6266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 271619/271619 [07:43<00:00, 586.43it/s]\n",
      "Validating Epoch 2: 100%|██████████| 53625/53625 [00:33<00:00, 1602.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss 4.1012, val_loss 3.6280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 271619/271619 [07:42<00:00, 587.60it/s]\n",
      "Validating Epoch 3: 100%|██████████| 53625/53625 [00:33<00:00, 1596.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss 4.0771, val_loss 3.5716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 271619/271619 [07:42<00:00, 587.81it/s]\n",
      "Validating Epoch 4: 100%|██████████| 53625/53625 [00:33<00:00, 1588.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss 4.0614, val_loss 3.5574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 271619/271619 [07:41<00:00, 588.83it/s]\n",
      "Validating Epoch 5: 100%|██████████| 53625/53625 [00:33<00:00, 1594.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss 4.0501, val_loss 3.5807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 271619/271619 [07:41<00:00, 588.15it/s]\n",
      "Validating Epoch 6: 100%|██████████| 53625/53625 [00:33<00:00, 1586.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss 4.0412, val_loss 3.5485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 271619/271619 [07:41<00:00, 588.59it/s]\n",
      "Validating Epoch 7: 100%|██████████| 53625/53625 [00:33<00:00, 1593.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss 4.0343, val_loss 3.5367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 271619/271619 [07:40<00:00, 589.52it/s]\n",
      "Validating Epoch 8: 100%|██████████| 53625/53625 [00:33<00:00, 1617.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss 4.0281, val_loss 3.5298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 271619/271619 [07:57<00:00, 568.92it/s]\n",
      "Validating Epoch 9: 100%|██████████| 53625/53625 [00:33<00:00, 1589.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss 4.0232, val_loss 3.5420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 271619/271619 [07:50<00:00, 577.33it/s]\n",
      "Validating Epoch 10: 100%|██████████| 53625/53625 [00:33<00:00, 1588.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss 4.0182, val_loss 3.5446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 271619/271619 [07:44<00:00, 584.23it/s]\n",
      "Validating Epoch 11: 100%|██████████| 53625/53625 [00:33<00:00, 1597.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_loss 4.0144, val_loss 3.5192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 271619/271619 [07:44<00:00, 584.51it/s]\n",
      "Validating Epoch 12: 100%|██████████| 53625/53625 [00:33<00:00, 1604.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss 4.0105, val_loss 3.5389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 271619/271619 [07:45<00:00, 583.95it/s]\n",
      "Validating Epoch 13: 100%|██████████| 53625/53625 [00:33<00:00, 1584.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss 4.0075, val_loss 3.5367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 271619/271619 [07:47<00:00, 581.19it/s]\n",
      "Validating Epoch 14: 100%|██████████| 53625/53625 [00:33<00:00, 1597.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss 4.0044, val_loss 3.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 271619/271619 [07:47<00:00, 580.92it/s]\n",
      "Validating Epoch 15: 100%|██████████| 53625/53625 [00:33<00:00, 1589.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_loss 4.0016, val_loss 3.5155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 271619/271619 [07:49<00:00, 578.97it/s]\n",
      "Validating Epoch 16: 100%|██████████| 53625/53625 [00:34<00:00, 1543.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_loss 3.9990, val_loss 3.5258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 271619/271619 [07:45<00:00, 583.48it/s]\n",
      "Validating Epoch 17: 100%|██████████| 53625/53625 [00:33<00:00, 1590.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_loss 3.9967, val_loss 3.5205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 271619/271619 [07:40<00:00, 589.68it/s]\n",
      "Validating Epoch 18: 100%|██████████| 53625/53625 [00:33<00:00, 1590.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train_loss 3.9945, val_loss 3.5187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 271619/271619 [07:54<00:00, 572.19it/s]\n",
      "Validating Epoch 19: 100%|██████████| 53625/53625 [00:33<00:00, 1592.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train_loss 3.9922, val_loss 3.5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 271619/271619 [07:40<00:00, 589.23it/s]\n",
      "Validating Epoch 20: 100%|██████████| 53625/53625 [00:33<00:00, 1592.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train_loss 3.9906, val_loss 3.5147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21: 100%|██████████| 271619/271619 [07:41<00:00, 588.50it/s]\n",
      "Validating Epoch 21: 100%|██████████| 53625/53625 [00:33<00:00, 1580.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train_loss 3.9888, val_loss 3.5101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22: 100%|██████████| 271619/271619 [07:42<00:00, 587.55it/s]\n",
      "Validating Epoch 22: 100%|██████████| 53625/53625 [00:33<00:00, 1594.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train_loss 3.9869, val_loss 3.5099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23: 100%|██████████| 271619/271619 [07:40<00:00, 589.46it/s]\n",
      "Validating Epoch 23: 100%|██████████| 53625/53625 [00:33<00:00, 1597.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train_loss 3.9854, val_loss 3.5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24: 100%|██████████| 271619/271619 [07:41<00:00, 588.21it/s]\n",
      "Validating Epoch 24: 100%|██████████| 53625/53625 [00:33<00:00, 1600.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train_loss 3.9838, val_loss 3.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25: 100%|██████████| 271619/271619 [07:42<00:00, 587.31it/s]\n",
      "Validating Epoch 25: 100%|██████████| 53625/53625 [00:33<00:00, 1601.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train_loss 3.9821, val_loss 3.5112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26: 100%|██████████| 271619/271619 [07:51<00:00, 576.10it/s]\n",
      "Validating Epoch 26: 100%|██████████| 53625/53625 [00:33<00:00, 1592.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train_loss 3.9809, val_loss 3.5058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27: 100%|██████████| 271619/271619 [07:41<00:00, 589.03it/s]\n",
      "Validating Epoch 27: 100%|██████████| 53625/53625 [00:33<00:00, 1595.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train_loss 3.9792, val_loss 3.5124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28: 100%|██████████| 271619/271619 [07:48<00:00, 579.92it/s]\n",
      "Validating Epoch 28: 100%|██████████| 53625/53625 [00:33<00:00, 1604.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train_loss 3.9779, val_loss 3.4963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29: 100%|██████████| 271619/271619 [07:41<00:00, 588.66it/s]\n",
      "Validating Epoch 29: 100%|██████████| 53625/53625 [00:33<00:00, 1605.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train_loss 3.9769, val_loss 3.5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30: 100%|██████████| 271619/271619 [07:42<00:00, 587.46it/s]\n",
      "Validating Epoch 30: 100%|██████████| 53625/53625 [00:33<00:00, 1587.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train_loss 3.9755, val_loss 3.5017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31: 100%|██████████| 271619/271619 [07:42<00:00, 587.41it/s]\n",
      "Validating Epoch 31: 100%|██████████| 53625/53625 [00:33<00:00, 1593.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train_loss 3.9741, val_loss 3.5081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32: 100%|██████████| 271619/271619 [07:43<00:00, 585.59it/s]\n",
      "Validating Epoch 32: 100%|██████████| 53625/53625 [00:33<00:00, 1597.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: train_loss 3.9730, val_loss 3.4929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33: 100%|██████████| 271619/271619 [07:48<00:00, 579.65it/s]\n",
      "Validating Epoch 33: 100%|██████████| 53625/53625 [00:33<00:00, 1589.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: train_loss 3.9718, val_loss 3.4955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34: 100%|██████████| 271619/271619 [07:44<00:00, 584.57it/s]\n",
      "Validating Epoch 34: 100%|██████████| 53625/53625 [00:33<00:00, 1597.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: train_loss 3.9702, val_loss 3.5019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35: 100%|██████████| 271619/271619 [07:47<00:00, 581.24it/s]\n",
      "Validating Epoch 35: 100%|██████████| 53625/53625 [00:33<00:00, 1587.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: train_loss 3.9694, val_loss 3.4970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36: 100%|██████████| 271619/271619 [07:43<00:00, 585.46it/s]\n",
      "Validating Epoch 36: 100%|██████████| 53625/53625 [00:33<00:00, 1606.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: train_loss 3.9684, val_loss 3.5038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37: 100%|██████████| 271619/271619 [07:44<00:00, 585.27it/s]\n",
      "Validating Epoch 37: 100%|██████████| 53625/53625 [00:33<00:00, 1591.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: train_loss 3.9674, val_loss 3.5064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38: 100%|██████████| 271619/271619 [07:46<00:00, 582.47it/s]\n",
      "Validating Epoch 38: 100%|██████████| 53625/53625 [00:33<00:00, 1610.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: train_loss 3.9662, val_loss 3.4915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39: 100%|██████████| 271619/271619 [07:40<00:00, 589.26it/s]\n",
      "Validating Epoch 39: 100%|██████████| 53625/53625 [00:33<00:00, 1607.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: train_loss 3.9652, val_loss 3.4972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41: 100%|██████████| 271619/271619 [07:41<00:00, 588.58it/s]\n",
      "Validating Epoch 41: 100%|██████████| 53625/53625 [00:33<00:00, 1601.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: train_loss 3.9631, val_loss 3.4908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46: 100%|██████████| 271619/271619 [07:39<00:00, 590.63it/s]\n",
      "Validating Epoch 46: 100%|██████████| 53625/53625 [00:33<00:00, 1594.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: train_loss 3.9587, val_loss 3.4935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49: 100%|██████████| 271619/271619 [07:43<00:00, 585.50it/s]\n",
      "Validating Epoch 49:  84%|████████▍ | 45115/53625 [00:28<00:05, 1592.96it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training Epoch 50: 100%|██████████| 271619/271619 [07:42<00:00, 587.07it/s]\n",
      "Validating Epoch 50: 100%|██████████| 53625/53625 [00:33<00:00, 1592.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: train_loss 3.9553, val_loss 3.4911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51: 100%|██████████| 271619/271619 [07:43<00:00, 585.52it/s]\n",
      "Validating Epoch 51: 100%|██████████| 53625/53625 [00:33<00:00, 1587.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: train_loss 3.9543, val_loss 3.4908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52:  13%|█▎        | 34030/271619 [00:57<06:39, 594.42it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training Epoch 52: 100%|██████████| 271619/271619 [07:43<00:00, 585.46it/s]\n",
      "Validating Epoch 52: 100%|██████████| 53625/53625 [00:33<00:00, 1602.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: train_loss 3.9534, val_loss 3.4919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53: 100%|██████████| 271619/271619 [07:44<00:00, 584.94it/s]\n",
      "Validating Epoch 53: 100%|██████████| 53625/53625 [00:33<00:00, 1588.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: train_loss 3.9523, val_loss 3.5035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54: 100%|██████████| 271619/271619 [07:42<00:00, 586.91it/s]\n",
      "Validating Epoch 54: 100%|██████████| 53625/53625 [00:33<00:00, 1592.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: train_loss 3.9520, val_loss 3.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55: 100%|██████████| 271619/271619 [07:46<00:00, 581.65it/s]\n",
      "Validating Epoch 55: 100%|██████████| 53625/53625 [00:33<00:00, 1594.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: train_loss 3.9512, val_loss 3.4943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56: 100%|██████████| 271619/271619 [07:44<00:00, 584.91it/s]\n",
      "Validating Epoch 56: 100%|██████████| 53625/53625 [00:33<00:00, 1582.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: train_loss 3.9505, val_loss 3.4905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57: 100%|██████████| 271619/271619 [07:42<00:00, 586.86it/s]\n",
      "Validating Epoch 57: 100%|██████████| 53625/53625 [00:33<00:00, 1600.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: train_loss 3.9495, val_loss 3.5015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58: 100%|██████████| 271619/271619 [07:41<00:00, 588.18it/s]\n",
      "Validating Epoch 58: 100%|██████████| 53625/53625 [00:33<00:00, 1597.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: train_loss 3.9484, val_loss 3.4944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59: 100%|██████████| 271619/271619 [07:42<00:00, 587.11it/s]\n",
      "Validating Epoch 59: 100%|██████████| 53625/53625 [00:33<00:00, 1597.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: train_loss 3.9480, val_loss 3.5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60: 100%|██████████| 271619/271619 [07:43<00:00, 585.65it/s]\n",
      "Validating Epoch 60: 100%|██████████| 53625/53625 [00:33<00:00, 1601.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: train_loss 3.9469, val_loss 3.4914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61: 100%|██████████| 271619/271619 [07:42<00:00, 587.47it/s]\n",
      "Validating Epoch 61: 100%|██████████| 53625/53625 [00:33<00:00, 1588.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: train_loss 3.9464, val_loss 3.4883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 62: 100%|██████████| 271619/271619 [07:41<00:00, 588.08it/s]\n",
      "Validating Epoch 62: 100%|██████████| 53625/53625 [00:33<00:00, 1590.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: train_loss 3.9460, val_loss 3.4915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63: 100%|██████████| 271619/271619 [07:41<00:00, 588.61it/s]\n",
      "Validating Epoch 63: 100%|██████████| 53625/53625 [00:33<00:00, 1603.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: train_loss 3.9453, val_loss 3.4880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 64: 100%|██████████| 271619/271619 [07:43<00:00, 586.45it/s]\n",
      "Validating Epoch 64: 100%|██████████| 53625/53625 [00:33<00:00, 1597.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: train_loss 3.9448, val_loss 3.4930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 65: 100%|██████████| 271619/271619 [07:44<00:00, 585.20it/s]\n",
      "Validating Epoch 65: 100%|██████████| 53625/53625 [00:33<00:00, 1601.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: train_loss 3.9439, val_loss 3.5008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 66: 100%|██████████| 271619/271619 [07:43<00:00, 586.43it/s]\n",
      "Validating Epoch 66: 100%|██████████| 53625/53625 [00:33<00:00, 1578.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: train_loss 3.9432, val_loss 3.5048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 67: 100%|██████████| 271619/271619 [07:44<00:00, 584.79it/s]\n",
      "Validating Epoch 67: 100%|██████████| 53625/53625 [00:33<00:00, 1579.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: train_loss 3.9425, val_loss 3.4962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 68: 100%|██████████| 271619/271619 [07:41<00:00, 588.76it/s]\n",
      "Validating Epoch 68: 100%|██████████| 53625/53625 [00:33<00:00, 1598.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: train_loss 3.9419, val_loss 3.4947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 69: 100%|██████████| 271619/271619 [07:47<00:00, 580.73it/s]\n",
      "Validating Epoch 69: 100%|██████████| 53625/53625 [00:33<00:00, 1596.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: train_loss 3.9412, val_loss 3.4967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 70: 100%|██████████| 271619/271619 [07:41<00:00, 589.10it/s]\n",
      "Validating Epoch 70: 100%|██████████| 53625/53625 [00:34<00:00, 1572.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: train_loss 3.9403, val_loss 3.4939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 71: 100%|██████████| 271619/271619 [07:42<00:00, 586.93it/s]\n",
      "Validating Epoch 71: 100%|██████████| 53625/53625 [00:33<00:00, 1588.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: train_loss 3.9394, val_loss 3.4983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 72: 100%|██████████| 271619/271619 [07:41<00:00, 588.23it/s]\n",
      "Validating Epoch 72: 100%|██████████| 53625/53625 [00:33<00:00, 1598.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: train_loss 3.9387, val_loss 3.4976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 73: 100%|██████████| 271619/271619 [07:42<00:00, 587.75it/s]\n",
      "Validating Epoch 73: 100%|██████████| 53625/53625 [00:33<00:00, 1605.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: train_loss 3.9385, val_loss 3.5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 74: 100%|██████████| 271619/271619 [07:42<00:00, 586.88it/s]\n",
      "Validating Epoch 74: 100%|██████████| 53625/53625 [00:34<00:00, 1570.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: train_loss 3.9377, val_loss 3.4966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 75: 100%|██████████| 271619/271619 [07:42<00:00, 587.91it/s]\n",
      "Validating Epoch 75: 100%|██████████| 53625/53625 [00:33<00:00, 1594.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: train_loss 3.9374, val_loss 3.4914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 76: 100%|██████████| 271619/271619 [07:41<00:00, 588.75it/s]\n",
      "Validating Epoch 76: 100%|██████████| 53625/53625 [00:33<00:00, 1587.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: train_loss 3.9366, val_loss 3.4931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 77: 100%|██████████| 271619/271619 [07:42<00:00, 587.02it/s]\n",
      "Validating Epoch 77: 100%|██████████| 53625/53625 [00:33<00:00, 1589.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: train_loss 3.9360, val_loss 3.4959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 78: 100%|██████████| 271619/271619 [07:42<00:00, 586.99it/s]\n",
      "Validating Epoch 78: 100%|██████████| 53625/53625 [00:33<00:00, 1593.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: train_loss 3.9354, val_loss 3.5021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 79: 100%|██████████| 271619/271619 [07:42<00:00, 587.33it/s]\n",
      "Validating Epoch 79: 100%|██████████| 53625/53625 [00:33<00:00, 1610.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: train_loss 3.9347, val_loss 3.4945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 80: 100%|██████████| 271619/271619 [07:42<00:00, 586.97it/s]\n",
      "Validating Epoch 80: 100%|██████████| 53625/53625 [00:33<00:00, 1593.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: train_loss 3.9339, val_loss 3.4952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 81: 100%|██████████| 271619/271619 [07:44<00:00, 584.94it/s]\n",
      "Validating Epoch 81: 100%|██████████| 53625/53625 [00:33<00:00, 1591.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: train_loss 3.9337, val_loss 3.5006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 82: 100%|██████████| 271619/271619 [07:42<00:00, 587.19it/s]\n",
      "Validating Epoch 82: 100%|██████████| 53625/53625 [00:33<00:00, 1597.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: train_loss 3.9329, val_loss 3.5068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 83: 100%|██████████| 271619/271619 [07:42<00:00, 587.55it/s]\n",
      "Validating Epoch 83: 100%|██████████| 53625/53625 [00:33<00:00, 1608.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: train_loss 3.9323, val_loss 3.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 84: 100%|██████████| 271619/271619 [07:41<00:00, 588.79it/s]\n",
      "Validating Epoch 84: 100%|██████████| 53625/53625 [00:33<00:00, 1597.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: train_loss 3.9320, val_loss 3.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 85: 100%|██████████| 271619/271619 [07:42<00:00, 587.42it/s]\n",
      "Validating Epoch 85: 100%|██████████| 53625/53625 [00:33<00:00, 1590.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: train_loss 3.9315, val_loss 3.4958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 86: 100%|██████████| 271619/271619 [07:43<00:00, 586.25it/s]\n",
      "Validating Epoch 86: 100%|██████████| 53625/53625 [00:33<00:00, 1604.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: train_loss 3.9310, val_loss 3.5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 87: 100%|██████████| 271619/271619 [07:41<00:00, 588.08it/s]\n",
      "Validating Epoch 87: 100%|██████████| 53625/53625 [00:33<00:00, 1606.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: train_loss 3.9302, val_loss 3.4950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 88: 100%|██████████| 271619/271619 [07:42<00:00, 587.37it/s]\n",
      "Validating Epoch 88: 100%|██████████| 53625/53625 [00:33<00:00, 1585.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: train_loss 3.9298, val_loss 3.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 89: 100%|██████████| 271619/271619 [07:41<00:00, 588.71it/s]\n",
      "Validating Epoch 89: 100%|██████████| 53625/53625 [00:33<00:00, 1587.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: train_loss 3.9291, val_loss 3.5044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 90: 100%|██████████| 271619/271619 [07:42<00:00, 586.68it/s]\n",
      "Validating Epoch 90: 100%|██████████| 53625/53625 [00:33<00:00, 1598.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: train_loss 3.9281, val_loss 3.4964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 91: 100%|██████████| 271619/271619 [07:42<00:00, 587.46it/s]\n",
      "Validating Epoch 91: 100%|██████████| 53625/53625 [00:33<00:00, 1598.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: train_loss 3.9282, val_loss 3.5010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 92: 100%|██████████| 271619/271619 [07:42<00:00, 587.09it/s]\n",
      "Validating Epoch 92: 100%|██████████| 53625/53625 [00:33<00:00, 1602.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: train_loss 3.9276, val_loss 3.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 93: 100%|██████████| 271619/271619 [07:43<00:00, 586.59it/s]\n",
      "Validating Epoch 93: 100%|██████████| 53625/53625 [00:33<00:00, 1594.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: train_loss 3.9269, val_loss 3.4985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 94: 100%|██████████| 271619/271619 [07:41<00:00, 588.77it/s]\n",
      "Validating Epoch 94: 100%|██████████| 53625/53625 [00:33<00:00, 1583.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: train_loss 3.9267, val_loss 3.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 95: 100%|██████████| 271619/271619 [07:42<00:00, 587.63it/s]\n",
      "Validating Epoch 95:  34%|███▍      | 18306/53625 [00:11<00:22, 1602.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [106]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_loss_list: List[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m valid_loss_list: List[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m train_loss_list, valid_loss_list \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_cnt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [102]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, valid_loader, optimizer, loss_fn, epoch_cnt)\u001b[0m\n\u001b[1;32m     40\u001b[0m batch_x \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     41\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m batch_y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 43\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred_y, batch_y)\n\u001b[1;32m     45\u001b[0m valid_batch_loss_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36mLSTM_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# lstm takes input of shape (batch_size, seq_len, input_size)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_3(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, hx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[0;32m--> 761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_weights_have_changed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    762\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_flat_weights()\n\u001b[1;32m    764\u001b[0m     orig_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:246\u001b[0m, in \u001b[0;36mRNNBase._weights_have_changed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m weights_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ref, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weight_refs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names):\n\u001b[0;32m--> 246\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ref() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m weight:\n\u001b[1;32m    248\u001b[0m         weights_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1601\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_backward_pre_hooks\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1599\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m-> 1601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1603\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_list: List[float] = []\n",
    "valid_loss_list: List[float] = []\n",
    "train_loss_list, valid_loss_list = train(\n",
    "    model=model, \n",
    "    train_loader=train_loader, \n",
    "    valid_loader=valid_loader, \n",
    "    optimizer=optimizer, \n",
    "    loss_fn=loss_fn, \n",
    "    epoch_cnt=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cefcf831-caf9-450f-a7c3-1db22c0fb21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss graph\n",
    "fig = plt.figure(figsize=(45, 5))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "train_loss_x_axis: List[int] = np.arange(len(train_loss_list)).tolist()\n",
    "valid_loss_x_axis: List[int] = np.arange(start=len(train_loss_list)-1, stop=-1, step=(len(train_loss_list)/len(valid_loss_list))*-1, dtype=np.float32).astype(np.int32).tolist()[::-1]\n",
    "\n",
    "ax1.set_title('Loss')\n",
    "ax1.plot(train_loss_x_axis, train_loss_list, marker='.')\n",
    "ax1.plot(valid_loss_x_axis, valid_loss_list, marker='.')\n",
    "ax1.legend(['train_loss', 'valid_loss'], loc='upper left')\n",
    "ax1.set_xlabel('1000 Batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4784e183-c84f-45ca-a97f-56dcb702f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"./models/cnn-lstm-currinfo-bs[{BATCH_SIZE}]-lr[{LEARNING_RATE}].pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf8890",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dae568b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, raw_df: pd.DataFrame, window_size: int) -> None:\n",
    "        super().__init__()\n",
    "        self.data: pd.DataFrame = raw_df.copy()\n",
    "        self.window_size: int = window_size\n",
    "        self.stock_dfs: Dict[int, pd.DataFrame]\n",
    "        self.idx_map: Dict[int, Dict[str, int]]\n",
    "        self.stock_dfs, self.idx_map = TimeSeriesDataset._SplitStockDataFrame(raw_df=self.data, window_size=self.window_size)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, _index: int) -> Tuple[np.ndarray, np.ndarray, int, int, int]:\n",
    "        '''\n",
    "        return x, y, date_id, seconds_in_buckets, stock_id\n",
    "        '''\n",
    "        index: int = _index\n",
    "        stock: int = self.idx_map[index]['stock']\n",
    "        stock_idx: int = self.idx_map[index]['idx']\n",
    "\n",
    "        start_idx, end_idx = stock_idx - (self.window_size - 1), stock_idx + 1\n",
    "        return TimeSeriesDataset._GenTimeSeriesData(raw_df=self.stock_dfs[stock].iloc[start_idx:end_idx])\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.idx_map)\n",
    "    \n",
    "    def FillTarget(self, stock: int, date: int, second: int, value: np.float32) -> None:\n",
    "        if stock not in self.stock_dfs:\n",
    "            return\n",
    "        self.stock_dfs[stock].loc[(self.stock_dfs[stock]['date_id'] == date) & (self.stock_dfs[stock]['seconds_in_bucket'] == second), 'pred_target'] = value\n",
    "    \n",
    "    @staticmethod\n",
    "    def _GenTimeSeriesData(raw_df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, int, int, int]:\n",
    "        '''\n",
    "        raw_df: The rows of time t-n ~ t for predicting the target of t.\n",
    "        The generated features contains the data of time t-n ~ t-1.\n",
    "        return x, y, date_id, seconds_in_buckets, stock_id\n",
    "        '''\n",
    "        df = raw_df.copy()\n",
    "        df = df.sort_values(by=['date_id', 'seconds_in_bucket'], ascending=True)\n",
    "\n",
    "        date: int = df['date_id'].tolist()[-1]\n",
    "        second: int = df['seconds_in_bucket'].tolist()[-1]\n",
    "        stock: int = df['stock_id'].tolist()[-1]\n",
    "        y: np.float32 = df['target'].tolist()[-1]\n",
    "\n",
    "        pred_target_not_null_indices = df['pred_target'].notnull()\n",
    "        df.loc[pred_target_not_null_indices, 'target'] = df.loc[pred_target_not_null_indices, 'pred_target']\n",
    "        \n",
    "        df = df[MODEL_INPUT_FEATURES]\n",
    "        df_numpy: np.ndarray = df.to_numpy()\n",
    "        df_numpy[-1, MODEL_INPUT_FEATURES.index('target')] = 0\n",
    "        \n",
    "        x: np.ndarray = df_numpy\n",
    "        \n",
    "        return x.astype(np.float32), np.array(y).astype(np.float32), date, second, stock\n",
    "    \n",
    "    @staticmethod\n",
    "    def _SplitStockDataFrame(raw_df: pd.DataFrame, window_size: int) -> Tuple[Dict[int, pd.DataFrame], Dict[int, Dict[str, int]]]:\n",
    "        stock_dfs: Dict[int, pd.DataFrame] = {}\n",
    "        idx_map: Dict[int, Dict[str, int]] = {}\n",
    "\n",
    "        data: pd.DataFrame = raw_df.copy()\n",
    "        data = data.sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id'], ascending=True)\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        data_idx_offset: int = 5 * 200\n",
    "\n",
    "        for stock in data['stock_id'].unique().tolist():\n",
    "            stock_df: pd.DataFrame = data.copy().loc[data['stock_id'] == stock]\n",
    "            stock_df.insert(stock_df.shape[1], 'new_idx', range(stock_df.shape[0]))\n",
    "            stock_df.insert(stock_df.shape[1], 'pred_target', np.nan)\n",
    "            for idx, row in stock_df.iterrows():\n",
    "                if row['new_idx'] < window_size:\n",
    "                    continue\n",
    "                stock_idx_map: Dict[str, int] = {'stock': stock, 'idx': row['new_idx']}\n",
    "                idx_map[int(idx) - data_idx_offset] = stock_idx_map\n",
    "            stock_df.reset_index(drop=True, inplace=True)\n",
    "            stock_df.drop('new_idx', axis=1, inplace=True)\n",
    "            stock_dfs[stock] = stock_df\n",
    "\n",
    "        return stock_dfs, idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2aa53399",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset: TimeSeriesDataset = TimeSeriesDataset(raw_df=test_pp_df, window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f00be8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[1.27902161e-02, 1.00000000e+00, 1.00025702e+00, 2.58485079e-02,\n",
      "        1.00061798e+00, 1.00046301e+00, 1.00000000e+00, 6.23286585e-04,\n",
      "        1.00036001e+00, 2.23703962e-02, 1.00000405e+00, 4.34994698e+00],\n",
      "       [1.22782132e-02, 1.00000000e+00, 1.00030899e+00, 2.58485079e-02,\n",
      "        1.00061798e+00, 1.00041199e+00, 1.00005102e+00, 6.18986692e-03,\n",
      "        1.00036001e+00, 2.99927648e-02, 1.00006902e+00, 3.99947166e+00],\n",
      "       [2.07656398e-02, 1.00000000e+00, 1.00000000e+00, 2.59973742e-02,\n",
      "        1.00061798e+00, 1.00020599e+00, 9.99639988e-01, 1.81533874e-03,\n",
      "        1.00010300e+00, 1.64251924e-02, 9.99655008e-01, 1.28901005e+01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 1.00046301e+00, 2.61507817e-02,\n",
      "        1.00046301e+00, 1.00046301e+00, 1.00015402e+00, 1.25529366e-02,\n",
      "        1.00051498e+00, 2.33828556e-02, 1.00020194e+00, 4.58955765e+00],\n",
      "       [3.03656887e-02, 1.00000000e+00, 1.00058401e+00, 9.85518750e-03,\n",
      "        1.00000000e+00, 1.00000000e+00, 9.99917984e-01, 9.01361834e-03,\n",
      "        1.00063598e+00, 2.01134793e-02, 1.00000000e+00, 0.00000000e+00]],\n",
      "      dtype=float32), array(-0.09000301, dtype=float32), 478, 0, 2)\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d99bf7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 1.0121399e-02, -1.0000000e+00,  9.9873298e-01,  1.4999378e-01,\n",
      "         9.9838299e-01,  9.9838299e-01,  9.9873298e-01,  9.5575508e-03,\n",
      "         9.9890798e-01,  6.2428858e-02,  9.9881601e-01, -1.9598007e+00],\n",
      "       [ 1.0121399e-02, -1.0000000e+00,  9.9873298e-01,  1.4999378e-01,\n",
      "         9.9838299e-01,  9.9838299e-01,  9.9873298e-01,  1.9949861e-02,\n",
      "         9.9890798e-01,  1.7002003e-01,  9.9880499e-01, -1.6599894e+00],\n",
      "       [ 9.9188332e-03, -1.0000000e+00,  9.9873298e-01,  1.5011580e-01,\n",
      "         9.9838299e-01,  9.9838299e-01,  9.9873298e-01,  1.8082341e-02,\n",
      "         9.9890798e-01,  1.8907678e-01,  9.9879599e-01, -2.3007393e-01],\n",
      "       [ 9.9188332e-03, -1.0000000e+00,  9.9873298e-01,  1.5011580e-01,\n",
      "         9.9838299e-01,  9.9838299e-01,  9.9873298e-01,  2.3210764e-02,\n",
      "         9.9890798e-01,  3.3625606e-01,  9.9878401e-01,  1.5103817e+00],\n",
      "       [ 2.9611750e-02, -1.0000000e+00,  9.9899602e-01,  1.3825254e-01,\n",
      "         9.9838299e-01,  9.9838299e-01,  9.9890798e-01,  1.9062987e-02,\n",
      "         9.9908298e-01,  1.0952274e-01,  9.9899697e-01,  1.2000000e+01]],\n",
      "      dtype=float32), array(-5.429983, dtype=float32), 478, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "# test_dataset.FillTarget(stock=0, date=477, second=540, value=np.float32(12))\n",
    "# print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "40334048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    model, test_set: TimeSeriesDataset\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    result: pd.DataFrame = pd.DataFrame(columns=['date_id', 'seconds_in_bucket', 'stock_id', 'time_id', 'row_id', 'target'])\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(test_set)) as pbar:\n",
    "            pbar.set_description(f\"Testing\")\n",
    "            for iter in range(len(test_set)):\n",
    "                batch_x, batch_y, date, second, stock = test_set[iter]\n",
    "\n",
    "                batch_x = torch.from_numpy(batch_x[np.newaxis, :]).to(device)\n",
    "                batch_y = torch.from_numpy(batch_y).to(device)\n",
    "                \n",
    "                pred_y = model(batch_x).cpu().detach().numpy()\n",
    "\n",
    "                for idx in range(len(pred_y)):\n",
    "                    test_set.FillTarget(stock=stock, date=date, second=second, value=pred_y[idx])\n",
    "                    curr_result: pd.DataFrame = pd.DataFrame.from_dict(data={\n",
    "                        'date_id': [date], \n",
    "                        'seconds_in_bucket': [second], \n",
    "                        'stock_id': [stock], \n",
    "                        'time_id': [int(26290 + (date - 478) * 55 + second)], \n",
    "                        'row_id': [f'{date}_{second}_{stock}'], \n",
    "                        'target': [pred_y[idx][0]]\n",
    "                    })\n",
    "                    if result.shape[0] > 0:\n",
    "                        result = pd.concat([result, curr_result], ignore_index=True)\n",
    "                    else:\n",
    "                        result = curr_result\n",
    "                pbar.update(1)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a35cd704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 33000/33000 [01:25<00:00, 387.07it/s]\n"
     ]
    }
   ],
   "source": [
    "test_result = test(model=model, test_set=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d65043b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26290</td>\n",
       "      <td>478_0_0</td>\n",
       "      <td>-0.169664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26290</td>\n",
       "      <td>478_0_1</td>\n",
       "      <td>-2.537034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26290</td>\n",
       "      <td>478_0_2</td>\n",
       "      <td>2.517469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26290</td>\n",
       "      <td>478_0_3</td>\n",
       "      <td>3.657625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26290</td>\n",
       "      <td>478_0_4</td>\n",
       "      <td>-0.749470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>195</td>\n",
       "      <td>26940</td>\n",
       "      <td>480_540_195</td>\n",
       "      <td>1.279591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>196</td>\n",
       "      <td>26940</td>\n",
       "      <td>480_540_196</td>\n",
       "      <td>0.200164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>197</td>\n",
       "      <td>26940</td>\n",
       "      <td>480_540_197</td>\n",
       "      <td>1.612261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>198</td>\n",
       "      <td>26940</td>\n",
       "      <td>480_540_198</td>\n",
       "      <td>1.571256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>199</td>\n",
       "      <td>26940</td>\n",
       "      <td>480_540_199</td>\n",
       "      <td>0.945384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_id  seconds_in_bucket  stock_id  time_id       row_id    target\n",
       "0          478                  0         0    26290      478_0_0 -0.169664\n",
       "1          478                  0         1    26290      478_0_1 -2.537034\n",
       "2          478                  0         2    26290      478_0_2  2.517469\n",
       "3          478                  0         3    26290      478_0_3  3.657625\n",
       "4          478                  0         4    26290      478_0_4 -0.749470\n",
       "...        ...                ...       ...      ...          ...       ...\n",
       "32995      480                540       195    26940  480_540_195  1.279591\n",
       "32996      480                540       196    26940  480_540_196  0.200164\n",
       "32997      480                540       197    26940  480_540_197  1.612261\n",
       "32998      480                540       198    26940  480_540_198  1.571256\n",
       "32999      480                540       199    26940  480_540_199  0.945384\n",
       "\n",
       "[33000 rows x 6 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "890b13c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_result = test_result.sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id'], ascending=True)\n",
    "test_out_result.drop(['date_id', 'seconds_in_bucket', 'stock_id'], axis=1, inplace=True)\n",
    "test_out_result.to_csv('./submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8783.773029,
   "end_time": "2023-12-25T17:44:38.390752",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-25T15:18:14.617723",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
