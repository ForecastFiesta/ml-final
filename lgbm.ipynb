{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from warnings import simplefilter\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import gc\n",
    "def data_preprocessing(df):\n",
    "    cols = [c for c in df.columns if c not in ['row_id', 'time_id']]\n",
    "    df = df[cols]\n",
    "\n",
    "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f'{c[0]}_minus_{c[1]}'] = (df[f'{c[0]}'] - df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_times_{c[1]}'] = (df[f'{c[0]}'] * df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_{c[1]}_imb'] = df.eval(f'({c[0]}-{c[1]})/({c[0]}+{c[1]})')\n",
    "\n",
    "    for c in combinations(prices, 3):\n",
    "        max_ = df[list(c)].max(axis=1)\n",
    "        min_ = df[list(c)].min(axis=1)\n",
    "        mid_ = df[list(c)].sum(axis=1)-min_-max_\n",
    "        df[f'{c[0]}_{c[1]}_{c[2]}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "\n",
    "    df.drop(columns=['date_id'], inplace=True)\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "def data_split_day(df:pd.DataFrame, _min, _max):\n",
    "    df = df[df['date_id'] < _max]\n",
    "    df = df[df['date_id'] >= _min]\n",
    "    return df\n",
    "\n",
    "def data_split_xy_and_data_preprocess(df:pd.DataFrame):\n",
    "    x = df.drop(['target'],axis=1)\n",
    "    x = data_preprocessing(x)\n",
    "    y = df[['target']]\n",
    "    return x, y\n",
    "\n",
    "# Read the dataset from a CSV file using Pandas\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df = df.dropna(subset=['target'])\n",
    "\n",
    "df_train = data_split_day(df, 0, 399)\n",
    "df_valid = data_split_day(df, 400, 478)\n",
    "df_tests = data_split_day(df, 478, 481)\n",
    "\n",
    "df_train_x, df_train_y = data_split_xy_and_data_preprocess(df_train)\n",
    "df_valid_x, df_valid_y = data_split_xy_and_data_preprocess(df_valid)\n",
    "df_tests_x, df_tests_y = data_split_xy_and_data_preprocess(df_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\tvalid_0's l1: 5.9661\n",
      "[20]\tvalid_0's l1: 5.94858\n",
      "[30]\tvalid_0's l1: 5.94158\n",
      "[40]\tvalid_0's l1: 5.93865\n",
      "[50]\tvalid_0's l1: 5.93717\n",
      "[60]\tvalid_0's l1: 5.93414\n",
      "[70]\tvalid_0's l1: 5.93243\n",
      "[80]\tvalid_0's l1: 5.93206\n",
      "[90]\tvalid_0's l1: 5.93169\n",
      "[100]\tvalid_0's l1: 5.93202\n",
      "[110]\tvalid_0's l1: 5.93143\n",
      "[120]\tvalid_0's l1: 5.93129\n",
      "[130]\tvalid_0's l1: 5.93146\n",
      "[140]\tvalid_0's l1: 5.93125\n",
      "[150]\tvalid_0's l1: 5.93116\n",
      "[160]\tvalid_0's l1: 5.93158\n",
      "[170]\tvalid_0's l1: 5.93167\n",
      "[180]\tvalid_0's l1: 5.93183\n",
      "[190]\tvalid_0's l1: 5.93207\n",
      "[200]\tvalid_0's l1: 5.93213\n",
      "[210]\tvalid_0's l1: 5.93222\n",
      "[220]\tvalid_0's l1: 5.93237\n",
      "[230]\tvalid_0's l1: 5.93266\n",
      "[240]\tvalid_0's l1: 5.9327\n",
      "[250]\tvalid_0's l1: 5.93277\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's l1: 5.93109\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.8, device=&#x27;cpu&#x27;, importance_type=&#x27;gain&#x27;,\n",
       "              max_depth=40, n_estimators=500, n_jobs=8, num_leaves=256,\n",
       "              objective=&#x27;mae&#x27;, reg_alpha=0.2, reg_lambda=3.25, subsample=0.6,\n",
       "              verbosity=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bytree=0.8, device=&#x27;cpu&#x27;, importance_type=&#x27;gain&#x27;,\n",
       "              max_depth=40, n_estimators=500, n_jobs=8, num_leaves=256,\n",
       "              objective=&#x27;mae&#x27;, reg_alpha=0.2, reg_lambda=3.25, subsample=0.6,\n",
       "              verbosity=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.8, device='cpu', importance_type='gain',\n",
       "              max_depth=40, n_estimators=500, n_jobs=8, num_leaves=256,\n",
       "              objective='mae', reg_alpha=0.2, reg_lambda=3.25, subsample=0.6,\n",
       "              verbosity=-1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "lgb_params = {\n",
    "        \"objective\": \"mae\",\n",
    "        \"n_estimators\": 500,\n",
    "        \"num_leaves\": 256,\n",
    "        \"subsample\": 0.6,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"learning_rate\": 0.1,\n",
    "        'max_depth': 40,\n",
    "        \"n_jobs\": 8,\n",
    "        \"device\": \"cpu\",\n",
    "        \"verbosity\": -1,\n",
    "        \"importance_type\": \"gain\",\n",
    "        \"reg_alpha\": 0.2,\n",
    "        \"reg_lambda\": 3.25\n",
    "    }\n",
    "LGB=LGBMRegressor(**lgb_params)\n",
    "\n",
    "LGB.fit(\n",
    "    df_train_x,  df_train_y,\n",
    "    eval_set=[(df_valid_x, df_valid_y)],\n",
    "    callbacks=[\n",
    "        lgb.callback.early_stopping(stopping_rounds=100),\n",
    "        lgb.callback.log_evaluation(period=10),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss :  6.274945251444542\n",
      "valid Loss :  5.93108832774886\n",
      "Test Loss :  5.228813033954659\n"
     ]
    }
   ],
   "source": [
    "pred_LGB = LGB.predict(df_train_x)\n",
    "print(\"Train Loss : \", mean_absolute_error(df_train_y, pred_LGB))\n",
    "\n",
    "pred_LGB = LGB.predict(df_valid_x)\n",
    "print(\"valid Loss : \", mean_absolute_error(df_valid_y, pred_LGB))\n",
    "\n",
    "pred_LGB = LGB.predict(df_tests_x)\n",
    "print(\"Test Loss : \", mean_absolute_error(df_tests_y, pred_LGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optiver2023.competition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptiver2023\u001b[39;00m\n\u001b[1;32m      2\u001b[0m env \u001b[38;5;241m=\u001b[39m optiver2023\u001b[38;5;241m.\u001b[39mmake_env()\n\u001b[1;32m      3\u001b[0m iter_test \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39miter_test()\n",
      "File \u001b[0;32m~/Documents/NCKU_SOC/2023-Fall-Courses/Machine-Learning/Homework/final/project/optiver2023/__init__.py:2\u001b[0m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompetition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_env\n\u001b[1;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmake_env\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optiver2023.competition'"
     ]
    }
   ],
   "source": [
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "counter=0\n",
    "\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    feat = data_preprocessing(test[[ 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
    "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size','far_price', 'near_price',\n",
    "       'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap','row_id']])\n",
    "    sample_prediction['target'] = LGB.predict(feat)\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-MpiU_v5V-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
